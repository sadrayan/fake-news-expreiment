{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Utilities to download and preprocess the Census data.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from six.moves import urllib\n",
    "import tempfile\n",
    "from io import StringIO\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://fakenews-259222-model/data/full_train.cvs\n",
      "gs://fakenews-259222-model/data/full_train.cvs\n",
      "num train:  (5826, 2)\n",
      "num test:  (5826, 3)\n",
      "(5826, 2)\n",
      "(5826, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>muslim organizations mosque kept ### ### raise...</td>\n",
       "      <td>money linda sarsour raised synagogue pittsburg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>says tony evers allowed middle school teacher ...</td>\n",
       "      <td>scott walker asks dpi begin license revocation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>gunman november #### mass shooting sutherland ...</td>\n",
       "      <td>church shooter southerland springs tx identifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7603</th>\n",
       "      <td>cesar sayoc stormy daniels worked florida stri...</td>\n",
       "      <td>cesar sayoc stormy daniels worked strip club e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>inmates orleans parish prison spent several da...</td>\n",
       "      <td>prisoners katrina olenka frenkiel bbc reporter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  claim  \\\n",
       "5226  muslim organizations mosque kept ### ### raise...   \n",
       "5390  says tony evers allowed middle school teacher ...   \n",
       "860   gunman november #### mass shooting sutherland ...   \n",
       "7603  cesar sayoc stormy daniels worked florida stri...   \n",
       "7270  inmates orleans parish prison spent several da...   \n",
       "\n",
       "                                                article  \n",
       "5226  money linda sarsour raised synagogue pittsburg...  \n",
       "5390  scott walker asks dpi begin license revocation...  \n",
       "860   church shooter southerland springs tx identifi...  \n",
       "7603  cesar sayoc stormy daniels worked strip club e...  \n",
       "7270  prisoners katrina olenka frenkiel bbc reporter...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def download (BUCKET_NAME):\n",
    "        # Storage directory\n",
    "    import tempfile\n",
    "    DATA_DIR = os.path.join(tempfile.gettempdir(), 'fakenews_data')\n",
    "\n",
    "    # Download options.\n",
    "    # https://storage.cloud.google.com/[BUCKET_NAME]/[OBJECT_NAME]\n",
    "    DATA_URL = ('gs://%s/data' % BUCKET_NAME)\n",
    "    TRAINING_FILE = 'full_train.cvs'\n",
    "    TRAINING_URL = '%s/%s' % (DATA_URL, TRAINING_FILE)\n",
    "\n",
    "    print(TRAINING_URL)\n",
    "\n",
    "    if (tf.io.gfile.exists(TRAINING_URL)):\n",
    "        print(TRAINING_URL)\n",
    "\n",
    "#     tf.io.gfile.copy(\n",
    "#         TRAINING_URL,\n",
    "#         'data/',\n",
    "#         overwrite=True\n",
    "#     )\n",
    "\n",
    "#     tf.gfile.GFile.r\n",
    "\n",
    "    with tf.gfile.GFile(TRAINING_URL, 'rb') as file:\n",
    "        train_df = pd.read_csv(StringIO( file.read().decode(\"utf-8\") ))\n",
    "        \n",
    "    return train_df\n",
    "\n",
    "def load_data(BUCKET_NAME):\n",
    "    train_df = download(BUCKET_NAME)\n",
    "\n",
    "    train_df = train_df.sample(frac=.10).reset_index(drop=True)\n",
    "\n",
    "    X = train_df[['claim', 'article']]\n",
    "    y = train_df['label']\n",
    "\n",
    "    # encode class values as integers\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    y = encoder.transform(y)\n",
    "    # convert integers to dummy variables (i.e. one hot encoded)\n",
    "    y = np_utils.to_categorical(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    print(\"num train: \", X_train.shape)\n",
    "    print(\"num test: \", y_train.shape)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_data(BUCKET_NAME)\n",
    "    \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCloud\n",
    "! export GOOGLE_APPLICATION_CREDENTIALS=\"/home/sonic/leadersprize/fakenews-40cea3fac9e2.json\"\n",
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/sonic/leadersprize/fakenews-40cea3fac9e2.json'\n",
    "# %env GOOGLE_APPLICATION_CREDENTIALS '/home/sonic/leadersprize/fakenews-40cea3fac9e2.json'\n",
    "\n",
    "PROJECT_ID = \"fakenews-259222\" #@param {type:\"string\"}\n",
    "BUCKET_NAME =  PROJECT_ID + \"-model\" #@param {type:\"string\"}\n",
    "REGION = \"us-central1\" #@param {type:\"string\"\n",
    "\n",
    "# # Only if your bucket doesn't already exist: Run the following cell to create your Cloud Storage bucket.\n",
    "# ! gsutil mb -l $REGION gs://$BUCKET_NAME\n",
    "# # ! gsutil acl set -R project-private gs://$BUCKET_NAME\n",
    "# ! gsutil ls -al gs://$BUCKET_NAME\n",
    "# # Update datasets\n",
    "# ! gsutil -m cp -r ../data/full_train.cvs gs://$BUCKET_NAME/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls -al gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/full_train.cvs')\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_URL = 'gs://fakenews-259222-model/data/full_train.cvs'\n",
    "    \n",
    "from io import StringIO\n",
    "with tf.gfile.GFile(TRAINING_URL, 'rb') as file:\n",
    "    train_df = pd.read_csv(StringIO( file.read().decode(\"utf-8\") ))\n",
    "\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
