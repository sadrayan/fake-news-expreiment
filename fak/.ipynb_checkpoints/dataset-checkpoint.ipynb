{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false          7408\n",
      "partly true    6451\n",
      "true           1696\n",
      "Name: labelCode, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>labelCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15550</th>\n",
       "      <td>The omnibus spending bill has \"9,427 pork barr...</td>\n",
       "      <td>John McCain</td>\n",
       "      <td>2009-02-25</td>\n",
       "      <td>17137</td>\n",
       "      <td>2</td>\n",
       "      <td>[82947, 93503]</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15551</th>\n",
       "      <td>Representative Maxine Waters said Muslims were...</td>\n",
       "      <td></td>\n",
       "      <td>2017-06-06</td>\n",
       "      <td>17138</td>\n",
       "      <td>0</td>\n",
       "      <td>[103780, 104726, 126025]</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15552</th>\n",
       "      <td>\"We were not, I repeat, were not told that wat...</td>\n",
       "      <td>Nancy Pelosi</td>\n",
       "      <td>2009-04-23</td>\n",
       "      <td>17139</td>\n",
       "      <td>0</td>\n",
       "      <td>[11331, 68915, 2186, 2185, 88418, 81950]</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15553</th>\n",
       "      <td>As of August 2017, members of the public could...</td>\n",
       "      <td></td>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>17140</td>\n",
       "      <td>2</td>\n",
       "      <td>[121353, 152864, 154411]</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15554</th>\n",
       "      <td>\"We don't get any of that information\" from th...</td>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>17141</td>\n",
       "      <td>1</td>\n",
       "      <td>[69545, 88929, 14698]</td>\n",
       "      <td>partly true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   claim      claimant  \\\n",
       "15550  The omnibus spending bill has \"9,427 pork barr...   John McCain   \n",
       "15551  Representative Maxine Waters said Muslims were...                 \n",
       "15552  \"We were not, I repeat, were not told that wat...  Nancy Pelosi   \n",
       "15553  As of August 2017, members of the public could...                 \n",
       "15554  \"We don't get any of that information\" from th...  Scott Walker   \n",
       "\n",
       "            date     id  label                          related_articles  \\\n",
       "15550 2009-02-25  17137      2                            [82947, 93503]   \n",
       "15551 2017-06-06  17138      0                  [103780, 104726, 126025]   \n",
       "15552 2009-04-23  17139      0  [11331, 68915, 2186, 2185, 88418, 81950]   \n",
       "15553 2018-05-14  17140      2                  [121353, 152864, 154411]   \n",
       "15554 2016-12-23  17141      1                     [69545, 88929, 14698]   \n",
       "\n",
       "         labelCode  \n",
       "15550         true  \n",
       "15551        false  \n",
       "15552        false  \n",
       "15553         true  \n",
       "15554  partly true  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_json ('data/train.json')\n",
    "labels = {0:'false', 1:'partly true', 2:'true'}\n",
    "\n",
    "def label(x):\n",
    "    return labels[x]\n",
    "\n",
    "train['labelCode'] = train.label.apply(label)\n",
    "\n",
    "\n",
    "print(train.labelCode.value_counts())\n",
    "\n",
    "train.labelCode.value_counts().plot(kind='bar')\n",
    "\n",
    "plt.show()\n",
    "train.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64969</th>\n",
       "      <td>79940</td>\n",
       "      <td>Rubio: Legalization first, border security whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64970</th>\n",
       "      <td>81412</td>\n",
       "      <td>Amid Health Law Expansion, Some States Trim Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64971</th>\n",
       "      <td>112386</td>\n",
       "      <td>Library of CongressSenate Committee Any Commit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64972</th>\n",
       "      <td>78733</td>\n",
       "      <td>Fort BraggFort Bragg is located just west of F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64973</th>\n",
       "      <td>93980</td>\n",
       "      <td>Obama's Russia Reset a 'Disaster'articleChess ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text\n",
       "64969   79940  Rubio: Legalization first, border security whe...\n",
       "64970   81412  Amid Health Law Expansion, Some States Trim Me...\n",
       "64971  112386  Library of CongressSenate Committee Any Commit...\n",
       "64972   78733  Fort BraggFort Bragg is located just west of F...\n",
       "64973   93980  Obama's Russia Reset a 'Disaster'articleChess ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(glob.glob(\"data/train_articles/*.txt\")[:100])\n",
    "files = [f for f in glob.glob(\"data/train_articles/*.txt\", recursive=True)]\n",
    "# print(files[:10])\n",
    "\n",
    "articles = []\n",
    "for file in files:\n",
    "    with open(file) as myfile:\n",
    "        data= \"\".join(line.rstrip() for line in myfile)\n",
    "        articles.append({'id' : os.path.basename(file)[:-4], 'text' : data})\n",
    "\n",
    "articles_df = pd.DataFrame.from_dict(articles)\n",
    "articles_df.reset_index(drop=True, inplace=True)\n",
    "# articles_df.set_index('id', inplace=True)\n",
    "\n",
    "articles_df.id = articles_df.id.astype(int)\n",
    "articles_df.text = articles_df.text.apply(str)\n",
    "# print(articles_df[articles_df.id == 112386]['text'])\n",
    "# print(articles_df.describe())\n",
    "\n",
    "articles_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15555it [00:42, 367.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77675</th>\n",
       "      <td>Charvat v. Resort Marketing Group, Inc. et al....</td>\n",
       "      <td>As of August 2017, members of the public could...</td>\n",
       "      <td></td>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77676</th>\n",
       "      <td>Update on Class-Action Lawsuit Over Cruise Com...</td>\n",
       "      <td>As of August 2017, members of the public could...</td>\n",
       "      <td></td>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77677</th>\n",
       "      <td>Gov. Scott Walker Previews Next Year In State ...</td>\n",
       "      <td>\"We don't get any of that information\" from th...</td>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77678</th>\n",
       "      <td>Wrong: Donald Trump says there's 'no system to...</td>\n",
       "      <td>\"We don't get any of that information\" from th...</td>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77679</th>\n",
       "      <td>David A. MartinA leading scholar in immigratio...</td>\n",
       "      <td>\"We don't get any of that information\" from th...</td>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 article  \\\n",
       "77675  Charvat v. Resort Marketing Group, Inc. et al....   \n",
       "77676  Update on Class-Action Lawsuit Over Cruise Com...   \n",
       "77677  Gov. Scott Walker Previews Next Year In State ...   \n",
       "77678  Wrong: Donald Trump says there's 'no system to...   \n",
       "77679  David A. MartinA leading scholar in immigratio...   \n",
       "\n",
       "                                                   claim      claimant  \\\n",
       "77675  As of August 2017, members of the public could...                 \n",
       "77676  As of August 2017, members of the public could...                 \n",
       "77677  \"We don't get any of that information\" from th...  Scott Walker   \n",
       "77678  \"We don't get any of that information\" from th...  Scott Walker   \n",
       "77679  \"We don't get any of that information\" from th...  Scott Walker   \n",
       "\n",
       "            date  label  \n",
       "77675 2018-05-14      2  \n",
       "77676 2018-05-14      2  \n",
       "77677 2016-12-23      1  \n",
       "77678 2016-12-23      1  \n",
       "77679 2016-12-23      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(train_df.iloc[0]['related_articles'][0])\n",
    "\n",
    "train_complete = []\n",
    "for index, row in tqdm(train.iterrows()):\n",
    "    for article in row['related_articles']:\n",
    "        train_complete.append(\n",
    "            {\n",
    "                'claim' : row['claim'],\n",
    "                'claimant' : row['claimant'],\n",
    "                'article' : articles_df.loc[articles_df['id'] == article].iloc[0]['text'],\n",
    "                'date' : row['date'],\n",
    "                'label' : row['label']\n",
    "            }\n",
    "        )\n",
    "#     break\n",
    "\n",
    "train_df = pd.DataFrame(train_complete)\n",
    "# print(train.loc[1])\n",
    "train_df.to_csv('data/full_train.cvs')\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average claim length 144.51996142719383\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average article length 6984.466186474589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f326f38c5f8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print('Average word length of claim in train is {0:.0f}.'.format(np.mean(train['claim'].apply(lambda x: len(x.split())))))\n",
    "# print('Average word length of article in train is {0:.0f}.'.format(np.mean(train['article'].apply(lambda x: len(x.split())))))\n",
    "\n",
    "train['length'] = train['claim'].apply(len)\n",
    "articles_df['length'] = articles_df['text'].apply(len)\n",
    "print('Average claim length', train.length.mean())\n",
    "train['length'].plot(bins=30, kind='hist')\n",
    "plt.show()\n",
    "print('Average article length', articles_df.length.mean())\n",
    "articles_df['length'].plot(bins=30, kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "max_features = 120000\n",
    "tk = Tokenizer(lower = True, filters='', num_words=max_features)\n",
    "tk.fit_on_texts(train['article'].values + train['claim'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['claim'].apply(lambda x: len(x.split())).plot(kind='hist', bins=10)\n",
    "plt.yscale('log')\n",
    "plt.title('Distribution of text length in characters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D \n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "import os, re, csv, math, codecs\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(0)\n",
    "\n",
    "DATA_PATH = '../input/'\n",
    "EMBEDDING_DIR = '../input/'\n",
    "\n",
    "MAX_NB_WORDS = 100000\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['.', ',', '\"', \"'\", ':', ';', '(', ')', '[', ']', '{', '}'])\n",
    "\n",
    "from subprocess import check_output\n",
    "# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load embeddings\n",
    "print('loading word embeddings...')\n",
    "embeddings_index = {}\n",
    "f = codecs.open('/home/sonic/.keras/datasets/wiki-news-300d-1M.vec', encoding='utf-8')\n",
    "for line in tqdm(f):\n",
    "    values = line.rstrip().rsplit(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('found %s word vectors' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "X = train_df[['claim', 'claimant']]\n",
    "y = train_df['label']\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y = np_utils.to_categorical(y)\n",
    "\n",
    "print(dummy_y)\n",
    "\n",
    "print(X.tail())\n",
    "# print(y.tail())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(\"num train: \", X_train.shape)\n",
    "print(\"num test: \", y_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\"true\", \"almost\", \"false\"]\n",
    "# y_train = train_df[label_names].values\n",
    "\n",
    "# #visualize word distribution\n",
    "# train_df['doc_len'] = train_df['comment_text'].apply(lambda words: len(words.split(\" \")))\n",
    "# max_seq_len = np.round(train_df['doc_len'].mean() + train_df['doc_len'].std()).astype(int)\n",
    "# sns.distplot(train_df['doc_len'], hist=True, kde=True, color='b', label='doc len')\n",
    "# plt.axvline(x=max_seq_len, color='k', linestyle='--', label='max len')\n",
    "# plt.title('comment length'); plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_docs_train = X_train['claim'].tolist()\n",
    "raw_docs_test = X_test['claim'].tolist() \n",
    "num_classes = len(label_names)\n",
    "\n",
    "X_train['doc_len'] =  X_train['claim'].apply(len)\n",
    "X_test['doc_len'] =  X_test['claim'].apply(len)\n",
    "\n",
    "max_seq_len = np.round(X_train['doc_len'].mean() + X_train['doc_len'].std()).astype(int)\n",
    "\n",
    "print(\"pre-processing train data...\")\n",
    "processed_docs_train = []\n",
    "for doc in tqdm(raw_docs_train):\n",
    "    tokens = tokenizer.tokenize(doc)\n",
    "    filtered = [word for word in tokens if word not in stop_words]\n",
    "    processed_docs_train.append(\" \".join(filtered))\n",
    "#end for\n",
    "\n",
    "processed_docs_test = []\n",
    "for doc in tqdm(raw_docs_test):\n",
    "    tokens = tokenizer.tokenize(doc)\n",
    "    filtered = [word for word in tokens if word not in stop_words]\n",
    "    processed_docs_test.append(\" \".join(filtered))\n",
    "#end for\n",
    "\n",
    "print(\"tokenizing input data...\")\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, lower=True, char_level=False)\n",
    "tokenizer.fit_on_texts(processed_docs_train + processed_docs_test)  #leaky\n",
    "word_seq_train = tokenizer.texts_to_sequences(processed_docs_train)\n",
    "word_seq_test = tokenizer.texts_to_sequences(processed_docs_test)\n",
    "word_index = tokenizer.word_index\n",
    "print(\"dictionary size: \", len(word_index))\n",
    "\n",
    "#pad sequences\n",
    "word_seq_train = sequence.pad_sequences(word_seq_train, maxlen=max_seq_len)\n",
    "word_seq_test = sequence.pad_sequences(word_seq_test, maxlen=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training params\n",
    "batch_size = 256 \n",
    "num_epochs = 8 \n",
    "\n",
    "#model parameters\n",
    "num_filters = 64 \n",
    "embed_dim = 300 \n",
    "weight_decay = 1e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding matrix\n",
    "print('preparing embedding matrix...')\n",
    "words_not_found = []\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        words_not_found.append(word)\n",
    "print('number of null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sample words not found: \", np.random.choice(words_not_found, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN architecture\n",
    "print(\"training CNN ...\")\n",
    "model = Sequential()\n",
    "model.add(Embedding(nb_words, embed_dim,\n",
    "          weights=[embedding_matrix], input_length=max_seq_len, trainable=False))\n",
    "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))  #multi-label (k-hot encoding)\n",
    "\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\n",
    "callbacks_list = [early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model training\n",
    "hist = model.fit(word_seq_train, y_train, batch_size=batch_size, \n",
    "                 epochs=num_epochs, callbacks=callbacks_list,\n",
    "                 validation_split=0.1, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(hist):\n",
    "    #generate plots\n",
    "    plt.figure()\n",
    "    plt.plot(hist.history['loss'], lw=2.0, color='b', label='train')\n",
    "    plt.plot(hist.history['val_loss'], lw=2.0, color='r', label='val')\n",
    "    plt.title('CNN ')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Cross-Entropy Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(hist.history['acc'], lw=2.0, color='b', label='train')\n",
    "    plt.plot(hist.history['val_acc'], lw=2.0, color='r', label='val')\n",
    "    plt.title('CNN ')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "# plot_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GlobalAveragePooling1D\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "model = Sequential()\n",
    "model.add(Embedding(nb_words, embed_dim,\n",
    "          weights=[embedding_matrix], input_length=max_seq_len, trainable=False))\n",
    "\n",
    "# we add a GlobalAveragePooling1D, which will average the embeddings\n",
    "# of all words in the document\n",
    "model.add(GlobalAveragePooling1D())\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(word_seq_train, y_train,\n",
    "          batch_size=batch_size, validation_split=0.1, \n",
    "          epochs=num_epochs)\n",
    "\n",
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = model.predict(word_seq_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "print('sklearn Macro-F1-Score:', f1_score(y_true, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "\n",
    "# define documents\n",
    "X = train_df['claim']\n",
    "y = train_df['label']\n",
    "\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(X)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = np.asanyarray(t.texts_to_sequences(X))\n",
    "print(encoded_docs)\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y = np_utils.to_categorical(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_docs, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(\"num train: \", X_train.shape)\n",
    "print(\"num test: \", X_test.shape)\n",
    "\n",
    "# print(encoded_docs)\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 200\n",
    "X_train = pad_sequences(X_train, maxlen=max_length, padding='post')\n",
    "X_test = pad_sequences(y_test, maxlen=max_length, padding='post')\n",
    "\n",
    "# print(X_train[1])\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('/home/sonic/.keras/datasets/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_length, trainable=False)\n",
    "model.add(e)\n",
    "# model.add(Flatten())\n",
    "\n",
    "# we add a GlobalAveragePooling1D, which will average the embeddings\n",
    "# of all words in the document\n",
    "model.add(GlobalAveragePooling1D())\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "hist = model.fit(X_train, y_train, epochs=10, verbose=1)\n",
    "# plot_history(hist)\n",
    "\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(y_pred.shape, y_pred[:10])\n",
    "\n",
    "print(np.unique(y_pred))\n",
    "\n",
    "\n",
    "def decode(data):\n",
    "    decoded = []\n",
    "    for i in range(data.shape[0]):\n",
    "        print('sssss', data[i], np.argmax(data[i]))\n",
    "        decoded.append(np.argmax(data[i]))\n",
    "        break\n",
    "    \n",
    "    return np.asanyarray(decoded)\n",
    "\n",
    "print(decode(y_pred)[:10])\n",
    "print()\n",
    "\n",
    "y_pred = decode(y_pred)\n",
    "y_true = decode(y_test)\n",
    "\n",
    "print(np.unique(y_pred))\n",
    "print(np.unique(y_true))\n",
    "print(y_pred)\n",
    "print(y_pred.shape)\n",
    "print(y_test.shape)\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# Results\n",
    "print('sklearn Macro-F1-Score:', f1_score(y_true, y_pred, average='macro'))\n",
    "print('sklearn Micro-F1-Score:', f1_score(y_true, y_pred, average='micro'))  \n",
    "print('sklearn weighted-F1-Score:', f1_score(y_true, y_pred, average='weighted'))  \n",
    "print('sklearn no average-F1-Score:', f1_score(y_true, y_pred, average=None))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.datasets import imdb\n",
    "\n",
    "\n",
    "def create_ngram_set(input_list, ngram_value=2):\n",
    "    \"\"\"\n",
    "    Extract a set of n-grams from a list of integers.\n",
    "    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=2)\n",
    "    {(4, 9), (4, 1), (1, 4), (9, 4)}\n",
    "    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=3)\n",
    "    [(1, 4, 9), (4, 9, 4), (9, 4, 1), (4, 1, 4)]\n",
    "    \"\"\"\n",
    "    return set(zip(*[input_list[i:] for i in range(ngram_value)]))\n",
    "\n",
    "\n",
    "def add_ngram(sequences, token_indice, ngram_range=2):\n",
    "    \"\"\"\n",
    "    Augment the input list of list (sequences) by appending n-grams values.\n",
    "    Example: adding bi-gram\n",
    "    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n",
    "    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017}\n",
    "    >>> add_ngram(sequences, token_indice, ngram_range=2)\n",
    "    [[1, 3, 4, 5, 1337, 2017], [1, 3, 7, 9, 2, 1337, 42]]\n",
    "    Example: adding tri-gram\n",
    "    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n",
    "    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017, (7, 9, 2): 2018}\n",
    "    >>> add_ngram(sequences, token_indice, ngram_range=3)\n",
    "    [[1, 3, 4, 5, 1337, 2017], [1, 3, 7, 9, 2, 1337, 42, 2018]]\n",
    "    \"\"\"\n",
    "    new_sequences = []\n",
    "    for input_list in sequences:\n",
    "        new_list = input_list[:]\n",
    "        for ngram_value in range(2, ngram_range + 1):\n",
    "            for i in range(len(new_list) - ngram_value + 1):\n",
    "                ngram = tuple(new_list[i:i + ngram_value])\n",
    "                if ngram in token_indice:\n",
    "                    np.append( new_list, token_indice[ngram])\n",
    "        new_sequences.append(new_list)\n",
    "\n",
    "    return np.asanyarray(new_sequences)\n",
    "\n",
    "# Set parameters:\n",
    "ngram_range = 2 #will add bi-grams features\n",
    "# ngram_range = 1\n",
    "max_features = 20000\n",
    "maxlen = 200\n",
    "batch_size = 32\n",
    "embedding_dims = 100\n",
    "epochs = 5\n",
    "\n",
    "print('Loading data...')\n",
    "# (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "print('Average train sequence length: {}'.format(np.mean(list(map(len, X_train)), dtype=int)))\n",
    "print('Average test sequence length:  {}'.format(np.mean(list(map(len, X_test)), dtype=int)))\n",
    "\n",
    "if ngram_range > 1:\n",
    "    print('Adding {}-gram features'.format(ngram_range))\n",
    "    # Create set of unique n-gram from the training set.\n",
    "    ngram_set = set()\n",
    "    for input_list in X_train:\n",
    "        for i in range(2, ngram_range + 1):\n",
    "            set_of_ngram = create_ngram_set(input_list, ngram_value=i)\n",
    "            ngram_set.update(set_of_ngram)\n",
    "\n",
    "    # Dictionary mapping n-gram token to a unique integer.\n",
    "    # Integer values are greater than max_features in order\n",
    "    # to avoid collision with existing features.\n",
    "    start_index = max_features + 1\n",
    "    token_indice = {v: k + start_index for k, v in enumerate(ngram_set)}\n",
    "    indice_token = {token_indice[k]: k for k in token_indice}\n",
    "\n",
    "    # max_features is the highest integer that could be found in the dataset.\n",
    "    max_features = np.max(list(indice_token.keys())) + 1\n",
    "\n",
    "    # Augmenting x_train and x_test with n-grams features\n",
    "    X_train = add_ngram(X_train, token_indice, ngram_range)\n",
    "    X_test = add_ngram(X_test, token_indice, ngram_range)\n",
    "    print('Average train sequence length: {}'.format(np.mean(list(map(len, X_train)), dtype=int)))\n",
    "    print('Average test sequence length: {}'.format(np.mean(list(map(len, X_test)), dtype=int)))\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "# x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "# x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('x_test shape:', X_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "model.add(Embedding(max_features ,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "\n",
    "# we add a GlobalAveragePooling1D, which will average the embeddings\n",
    "# of all words in the document\n",
    "model.add(GlobalAveragePooling1D())\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
