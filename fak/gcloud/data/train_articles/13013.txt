ADGN: An Algorithm for Record Linkage Using Address, Date of Birth, Gender, and Name
As a contribution to the statistical literature on databases and matching, we have four goals in this article. First, the simple, deterministic analysis herein provides a baseline against which to measure other methodologies, such as those using probabilistic approaches or statistical optimization. (For a review and categorization of approaches, see Christen and Goiser [ 2007 Christen, P., and Goiser, K. (2007), “Quality and Complexity Measures for Data Linkage and Deduplication,�? in Quality Measures in Data Mining , eds. F. Guillet, and H. J. Hamilton, Berlin: Springer, pp. 127–152.].) Second, the analysis includes estimates of false negative and false positive rates that occur with this matching methodology. Knowing the false positive and false negative rates are important for designing future studies, especially in choosing a methodology for matching. Third, this article presents statistics (actual data and information, not just theory) on the uniqueness of specific identifiers and fields in databases. Such statistics are critical for understanding the matchability of databases and the identifiability of individual records in databases, and these facts about personal databases are not common in the literature. Finally, this article describes a significant empirical application of database matching to law and public policymaking in the United States and shows how the application of data sciences informed an important controversy in American law.

Using multiple indicators offers a method for minimizing nonmatches due to missing data, typographical errors, or variations in names and addresses. No single field determines whether a match occurs. The success of this approach, ultimately, depends on the uniqueness of the identifiers. Even in a large state, such as Texas, combinations of triplets of A, D, G or N proved to have a very high rate of uniqueness. This approach differs from probability-based methods, such as using fuzzy matching in constructing linkage indicators (Guth 1976 Guth, G. J. A. (1976), “Surname Spellings and Computerized Record Linkage,�? Historical Letters Newsletter , 10, 10–19.; De Brou and Olsen 1986 De Brou, D., and Olsen, M. (1986), “The Guth Algorithm and the Nominal Record Linkage of Multi-Ethnic Populations,�? Historical Methods , 19, 20–24.), or scoring criteria for identifying the likelihood of a match (Belin and Rubin 1995 Belin, T., and Rubin, D. B. (1995), “A Method for Calibrating False-Match Rates in Record Linkage,�? Journal of the American Statistical Association , 90, 694–707.; Larsen and Rubin 2001 Larsen, M. D., and Rubin, D. B. (2001), “Iterative Automoated Record Linkage Using Mixture Models,�? Journal of the American Statistical Association , 96, 32–41.). Fuzzy matching and probabilistic criteria also are designed to address issues of inconsistently recorded information, missingness and typographical errors. These methods, however, can be computationally very intensive and slow, rendering them impractical for the short timeframes necessary in court litigation. Additionally, in practice, canned probabilistic software may lead researchers to make trade-offs between false positives and false negatives that are not appropriate for the specific research question at hand.

To validate the algorithm, we benefited from one unusual feature of the data: a subset of the voter registration records contained nine-digit Social Security Numbers and/or driver license numbers, identifiers that were also available in some of the databases to which we were linking. This allowed us to determine that 98% of records that matched to SSN also matched using some combination of three of A, D, G, and N. Similarly, 98% of those that matched using ADGN were subsequently matched using SSN9. Inspection of the data after matching reveal only a small percent of false positives.

Working on behalf of the United States in its litigation against the state of Texas, we developed a robust algorithm, building on prior work by Sweeney ( 2002 Sweeney, L. (2002), “ k -Anonymity: A Model for Protecting Privacy,�? International Journal of Unicertaity, Fuzziness, and Knowledge-Based Systems , 10, 557–570.), for matching databases using information in the Address (A), Date of Birth (D), Gender (G), and Name (N) fields. The algorithm, first, standardizes databases. Second, multiple identifiers are constructed using information from all four A, D, G, and N fields as well as triplets of those four fields (i.e., ADG, ADN, DGN). Finally, two records are considered a match if there is an exact match to any one of the multiple indicators. Using multiple indicators constructed from ADGN, the voter registration file from the Texas Election Administration Management system (TEAM) was matched to databases of acceptable forms of state and federal identification, specifically, the Department of Public Safety (DPS) list of driver licenses, state IDs, and concealed handgun permits, the Department of State list of passports, the Department of Defense lists of military personnel (with active military ID), the Department of Veterans Affairs lists of veteran identification holders, the Social Security Administration disability list, and the Immigration and Naturalization lists of naturalized citizens with immigration papers. The number of records for which no matching record on one of the identification files could be found measured the number of people presumed to lack an acceptable ID under Texas law.

The social science problem presented in the Texas case is, in fact, one of the most important database management issues today. How can researchers link records across multiple databases with personal information in the absence of a unique common identifier, typically nine digit Social Security Numbers (SSN9)? Most states have a unique identifier tied to a voter registration record that helps match snapshots of voter files taken at different points in time (Christen 2014 Christen, P. (2014), “Preparation of a Real Temporal Voter Data Set for Record Linkage and Duplicate Detection Research,�? Working Paper.). But those identifiers are not also used by motor vehicle registries or other database systems. Some states, such as Georgia, maintain a common identifier to link records across databases maintained by the state government (Hood III and Bullock III 2008 Hood III, M., and Bullock III, C. S. (2008), “Worth a Thousand Words? An Analysis of Georgia’s Voter Identification Statute,�? American Politics Research , 36, 555–579.). But identifiers like these are often unavailable or are sufficiently incomplete that they are not useful for matching. The challenge is how to use personal information, such as names, addresses, and dates of birth, that are available on all files to link the databases in a manner that minimizes the rates of false positives (matches between files that in fact correspond to different individuals) and false negatives (failure to match records on two files that correspond to the same individual; Fellegi and Sunter 1969 Fellegi, I. P., and Sunter, A. B. (1969), “A Theory of Record Linkage,�? Journal of the American Statistical Association , 64, 1183–1210.).

The Texas registration-to-ID empirical investigation is one of the largest database matching efforts ever conducted in which information about the match rates and uniqueness of specific identifiers is publicly available. It offers a unique picture of the identifiability of individuals and the matchability of public databases using commonly recorded personal information, such as names and dates of birth. As a result, what we learn about the identifiability of individuals from this example not only sheds light on the policy questions about voter ID raised by the particular court case, but it also sheds lights on policies concerning data privacy and data management. The empirical task in the Texas case was first to estimate what percent of people would be affected by S. B. 14 (i.e., likely voters who lack a qualifying ID) and then to estimate whether the implementation of the law was more likely to affect registered Black and Hispanic voters than registered White voters. What we learn about the ability to link records with a high degree of accuracy is informative for research and applications in a range of areas from voting rights to public health to criminology to marketing to government censuses.

In 2011, the Texas State Legislature passed Senate Bill 14 (S. B. 14), which required voters to show one of six forms of government-issued photo identification: a state driver’s license or ID card, a concealed handgun license, a U.S. passport, a military ID card, or a U.S. citizenship certificate with a photo. The law carved out exceptions for older people and people with disabilities, but it was one of the strictest voter identification laws in the country. 1 1 See, for example, Manny Fernandez and Erik Eckholm, “Federal Court Rules Texas’ ID Law Violates Voting Rights Act,�? New York Times , July 20, 2016. View all notes The Department of Justice refused to grant pre-clearance of the law under Section 5 of the Voting Rights Act. Texas sued, and a four-year legal battle began. Texas lost that original suit, Texas v. Holder , as well as a subsequent suit under Section 2 of the Voting Rights Act, Veasey v. Abbott , of intentional racial discrimination. To gauge how many voters lack the requisite ID and whether the law would have racially disparate effects, both the State of Texas and the Department of Justice conducted database-matching of the 13 million records on the Texas Election Administration Management (TEAM) voter file with the 25-million-record file of State of Texas IDs and various national lists maintained by the federal government.

Typographical errors and erroneous fields arise because of keystroke errors in databases. They may occur at a low frequency, but will reduce the accuracy of the matching process. They may be particularly common in databases like voter registration files, where citizens often submit hand-written applications for registration and clerks record the fields into a database. Errors and inconsistencies in fields will create false negatives, non-matches that should be matches, because the entry in one segment of A-D-G-N on one of the databases is incorrect and does not match the A-D-G-N in the target database with which a match is sought. Even when the incidence of key-punching errors is low, the probability of at least one error in a series of multiple indicators is not trivial. Erroneous fields, such as invalid numbers, also arise. For example, SSN9 fields sometimes contain 111111111, 123456789 or 999999999, which are invalid SSN9s.

Inconsistent data fields arise for many reasons, such as alternative spellings of names, nicknames, name changes, and alternative addresses. A person may use a nickname on one file and a proper first name in another file. Name inconsistencies arise often with first names, and also when people marry and take the names of their spouses. Address fields also exhibit inconsistencies from one file to another. A person may use a home address in one file and a business address in another. Address fields, such as street suffixes and apartment numbers, are not treated similarly across databases. The data are often correct; the individual may simply be identified in different ways.

In the October 2016 voter list from Texas, out of 7,880,488 unique individuals, 19,172 were missing a residential ZIP code (though many of these had a mailing ZIP code), 16,208 were missing a street number, none were missing a listed birthdate, though, for instance, 5196 individuals had a birthday listed as January 1, 1900. Some individuals were missing gender, but gender is easily imputable by first names. For the records containing gender, we calculate the percentage of each first name that is female, and assign female to names that are likely to be female but who are listed without a gender designation. We do the same for male names.

If ZIP code, gender, date of birth, and last name were always available and always consistent across databases, our work would be done. Alas, in practice, a linkage strategy must deal with three common data recording issues: missing fields, inconsistent data fields, and typographical errors. Incomplete or missing fields will mean that the complete Identifier A-D-G-N cannot be constructed. If Date of Birth is missing, the D-portion is blank. If an exact match is the criterion, then a false negative may be generated because no match is possible on account of the missing data.

Combining these four pieces of information, assuming they are independent, reveals that the ZIP5, Gender, DOB, and Last Name of an individual is unique to 1 in 2.7 billion individuals. The risk of a nonunique individual identified by these characteristics, then, is less than.003. 2 2 That is, (1/2.7 billion)/(1/7.9 million). View all notes Hence, Address-DOB-Gender-Name (just last name) will almost surely identify every individual on a large data file, such as the State of Texas Voter File and Department of Public Safety Identification file, and can be used to link records across the databases. Even three pieces of information can almost surely identify people.

Fourth, consider Name. The most common last name (ignoring first names) in the State of Texas voter file is Smith, which 73,971, or a little less than 1 out of 100 persons have. Matching on last name is quite powerful. In addition, first names and middle names refine the name field further. The most common First Name-Last Name combination in Texas is Maria Garcia, held by 1914 voters. Adding the middle initial, the most common combination is Maria D. Garcia, a named shared by 296 of 7,880,488 voters.

Second, consider Date of Birth (DOB). The most common Birth Year on the Texas voter file is 1957, which contains approximately 1 in 50 people. The most common Date of Birth is August 30, 1960, which 652 persons share.

First, consider just one piece of information from addresses—five-digit ZIP Code (ZIP5). In the State of Texas, there are 2,257 five-digit ZIP Codes listed in the 2016 voter list. Not every ZIP5 contains exactly the same number of voters. The most common ZIP Code is 75070, which has 32,724 persons. The five-digit zipcode alone reduces the dimensionality of the problem tremendously, from 1 in 8 million to 1 in 33,000. The uniqueness of address information can be refined further by using street number (that is the number of the building in which a person lives). The most common street number in Texas is #201. 16,199 Texas voters, or 0.2%, have that street number in the state of Texas. All other numbers are less common. The most common ZIP5-street number combination is street number 6 in ZIP code 77381, which is shared by 558 persons. All other combinations are less common.

Before proceeding with this exercise, a note about data. Most of the analysis in this article comes from the expert reports filed in court proceedings and are based on our analysis of the databases from the trial. In preparation for this article, however, we obtained (in October 2016, through a public records request) an additional copy of the Texas voter file. This file allows us to do some additional analysis of the Texas file beyond what we did while serving as experts. Note, however, that the file we obtained in 2016 is not the full statewide list of 13.5 million registrants. Instead, Texas transmitted the vote history file of 7.9 million individuals. This file does not list individuals who are registered but failed to cast ballots in recent elections. For the illustrative purposes below (i.e., to study the uniqueness of various fields), a database of 7.9 million records is sufficiently large (larger than the complete voter files of all but a handful of states) to make the point.

The ability to link records with a high level of accuracy depends on the frequency with which pieces of information on lists, such as names and ZIP codes, occur in the population. The more unique a characteristic the more power it offers for record linkage. Combining information from different fields increases the power further. Some basic statistics from the Texas data files can help us understand which fields are particularly powerful for matching. The following exercise reveals that information extracted from the address, date of birth, gender, and name fields can almost surely identify individuals uniquely.

In the Texas case, our goal was matchability—to determine what percent of people on one database (TEAM) appear in other databases, and whether the appearance on TEAM but not another database was correlated with race. The lessons of that research carry over to identifiability. In particular, the ability to identify individual records in any database and to link that individual’s records across databases can have both harms and benefits to the person whose information is at stake. There are benefits that come from empowering the individual or the people working on her or his behalf to better manage personal data. There is the threat or harm of identity theft, as might happen if one’s financial records are breached. There is also the harm of excessive government surveillance or overreach, such as through predictive policing. There is also the harm that might result if private and sensitive information is released, say, revealing private communications to an employer or health records to an insurance company. The ability to identify an individual’s information in multiple datasets and to link those datasets, then, has value to the individual to the extent that it allows her or him to manage and/or protect personal information.

The second objective—identifiability—is to link databases to find an individual and extract that person’s information. In that context, the decision rule for what counts as a match may differ. For example, in linking health records across providers, the critical statistic might be the incidence of false positive matches, as any false positive might be life-threatening. Not surprisingly, many of the advances in record linkage and database matching have come out of the fields of health care, but they have spread to other areas (Pacheco et al. 2008 Pacheco, A. G., Saraceni, V., Tuboi, S. H., H. Moulton, L., Chaisson, R. E., Cavalcante, S. C., Durovni, B., Faulhaber, J. C., Golub, J. E., King, B., Mauro, S., and Harrison, L. H. (2008), “Validation of a Hierarchical Deterministic Record-Linkage Algorithm Using Data From 2 Different Cohorts of Human Immunodeficiency Virus-Infected Persons and Mortality Databases in Brazil,�? American Journal of Epidemiology , 168, 1326–1332.; Mohanty et al. 2017 Mohanty, A. F., Crook, J., Porucznik, C., Johnson, E. M., Rolfs, R. T., and Sauer, B. C. (2017), “Development and Evaluation of a Record LinkageProtocol for Utah’s Controlled Substance Database,�? Health Informatics Journal , 23, 35–43.). In the social sciences, when linking survey respondents to public records for the purpose of studying individual-level correlates (as opposed to studying population estimates), reducing false positives is typically the priority (e.g., Hersh and Goldenberg 2016 Hersh, E., and Goldenberg, M. (2016), “Democratic and Republican Physicians Provide Different Care on Politicized Health Issues,�? Proceedings of the National Academy of Science , 113, 11811–11816.; Ansolabehere and Hersh 2012 Ansolabehere, S., and Hersh, E. (2012), “Validation: What Survey Misreporting Reveal about Survey Misreporting and the Real Electorate,�? Political Analysis , 20, 437–459.). When the goal is identifiability, the minimization of false positives might be so important that the algorithm should tolerate a much higher rate of false negatives to avoid false positives.

The goal of the first objective—matchability—is to measure features of the population represented by that database. For example, the U.S. Census Bureau in 1980 and 1990 matched the Post Enumeration Survey to the Enumeration datafile to estimate the size of the population missed by the enumeration (Winkler 1999 Winkler, W. E. (1999), “The State of Record Linkage and Current Research Problems,�? Census Bureau Research Report Series (#93-8), Statistical Research Division, U.S. Census Bureau., 2006 ——— (2006), “Overview of Record Linkage and Current Research Directions,�? Census Bureau Research Report Series (Statistics #2006-2). Statistical Research Division, U.S. Census Bureau.; Larsen and Rubin 2001 Larsen, M. D., and Rubin, D. B. (2001), “Iterative Automoated Record Linkage Using Mixture Models,�? Journal of the American Statistical Association , 96, 32–41.). In such research, the effort is to develop an unbiased estimate, so researchers might tolerate some random error in the matching process—that is, some false positives—so long as those are balanced by false negatives (Belin and Rubin 1995 Belin, T., and Rubin, D. B. (1995), “A Method for Calibrating False-Match Rates in Record Linkage,�? Journal of the American Statistical Association , 90, 694–707.). In our effort on behalf of the Justice Department, our goal was analytics: we sought to determine the percent of people on the voter list who have an ID and to determine how that percent varied by racial group. We sought to minimize false positives and false negatives. Some were unavoidable but we sought to reduce them to be well below the observed rate of true nonmatches and well below the racial differential in such nonmatches.

Record linkage is performed with two different objectives: matching of entire databases (“matchability�?) and identification of individuals (“identifiability�?). Both of these applications seek to link databases with a high degree of accuracy. By accuracy, we mean that record linkage algorithms seek to minimize false positives (matches of two records that correspond to different individuals) and false negatives (non-matched records when the individual is, in fact, on both lists) (Fellegi and Sunter 1969 Fellegi, I. P., and Sunter, A. B. (1969), “A Theory of Record Linkage,�? Journal of the American Statistical Association , 64, 1183–1210.; Belin and Rubin 1995 Belin, T., and Rubin, D. B. (1995), “A Method for Calibrating False-Match Rates in Record Linkage,�? Journal of the American Statistical Association , 90, 694–707.). The same technology is usually deployed for each purpose, but whether the goal is matchability or identifiability can affect certain trade-offs between minimizing false positives and minimizing false negatives.

3. Matching process

The matching algorithm proceeds in four parts.

Database Preparation. Databases are prepared and standardized.

Creation of Identifiers. Identifier values used to link records in one database to records in another database are constructed by combining multiple individual fields.

Record Linkage and Matching. One-to-many matches are conducted between the databases. That is, the algorithm matches each unique identifier on the TEAM database to all records on the identification database that have the corresponding value of the identifier. (One-to-one matching may alternatively be appropriate depending on the particular features of the matching databases.)

Data Gathering. Appended to the voter file data are fields indicating every match found to a record on a state or federal database.

The result of this methodology is to produce a MATCH list and a NO MATCH list. This section describes the algorithm and results of the matching process in greater detail.

The first phase of the matching algorithm, Database Preparation, standardizes the coding of database fields to facilitate matching. Different databases store the fields in different ways. The database preparation in the algorithm standardizes the coding of dates of birth, genders, addresses and names, and identifies invalid or missing values (such as 111111111 for Social Security Numbers). Invalid identifiers are discovered by assessing frequencies of duplicates by identifier. As stated above, an identifier like month-day-year of birth ought to be distributed predictably across a population. Birthdays that occur at unusually high rates often indicate an issue like birthdays listed as 01/01/1901 or 11/11/1111. Analysis of duplicates also reveals completely duplicate cases. In the Texas voter file, we identified approximately two hundred records in which all information was identical.

Standardization of addresses involved extracting just the ZIP5 and street number fields. ZIP5 and street numbers are useful components of an address field because they are numeric and they are stored similarly across databases. Other components of addresses, like street names, street suffix, and apartment number pose difficulties because they are stored differently in different databases (e.g., First Street vs. 1st Street vs. First ST, etc.), and because fields composed of lengthy strings will have higher incidence of typos.

Standardization of dates of birth involved converting all fields to Month-Day-Year combinations.

Standardization of Gender coded all indicators of Male to 0 and all indicators of Female to 1.

Standardization of names involved the most attention to subtle details. We constructed two different name indicators, one for Last Names only and the other for Last Name, First Name, and Middle Initial. The latter offered a higher level of uniqueness but also more false negatives owing to variations in first names, especially due to nicknames. Rather than use a name dictionary for first names and nicknames, we simply altered the identification fields. Standardization of last names required several procedures. First, all names were converted to uppercase letters. Second, the algorithm removed all apostrophes, hyphens, and other markings. For examples, the last name O’Conner occurs as O’CONNER in some databases and OCONNER in others; elimination of extraneous marks changes all such cases to OCONNER. A variant on the name matches accounted for variations in usage of hyphenated or compound last names, such as maiden names used as middle names. In addition to attempting matches on last names, we broke each hyphenated name into two parts and attempted to find matching records using each name. Third, all spaces in last names were removed. VAN HALEN or De La Rosa became VANHALEN and DELAROSA. Fourth, signifiers such as II, III, IV, and JR were removed from the ends of names, as these are often not standard.

The second part of the algorithm develops multiple identifiers for purposes of record linkage. The algorithm builds identifiers by combining fields related to Address, Date of Birth, Gender, and Name. In total, six different primary identifiers were constructed in the registration database (TEAM) and in the license database (DPS). Each identifier corresponds to a particular combination of fields. For example, Combination A consists of First Name, Last Name, Date of Birth, Gender, Street Number, and 5-digit ZIP Code. A sample version of Combination A for a man named John Smith, born on January 1, 1960, and living at 100 Main Street in the ZIP Code 78610 would be JOHNSMITH00101196010078610.33 Specifically, that breaks down as First Name: JOHN + Last Name: SMITH + Gender = 0 (Male) + Birth Month: 01 (January) + Birth Day: 01 (the First) + Birth Year: 1960 + Street Number: 100 + ZIP5: 78610.View all notes Importantly, each of these indicators is nearly always uniquely identifying, so long as data are not missing in the component parts. To illustrate this, consider Figure 1. The calculations shown here are similar to ones we performed based on the original Texas file, but these come from the 2016 voter list obtained from Texas. The figure shows 17 combinations of components of A-G-D-N, some of which we did use in matching and some of which we did not. There are a number of potential combinations that are not unique to individuals. For example, first name + last name or first name + last name + gender are only unique to about 50% of registered voters. Street Number + Zipcode + gender is only unique to about 20% of voters. However, all of the combinations that we used in our algorithm were unique for over 99% of registered voters. This is important because it means that if a person is identified in another database with the same combination, it is very unlikely that this is a different person from the one we are trying to link.

Figure 1. Percent unique of A-G-D-N combinations in the Texas voter file.

The third stage of the process, the Record Linkage and Matching phase, conducts one-to-many matches and performs multiple sweeps for each identifier (ADGN, ADG, ADN, DGN). That is, a match was said to exist for each record in TEAM for which one or more records could be found in a corresponding database. We utilized one-to-many matches because the matching databases (particularly the motor vehicle databases) contain multiple records per person. Multiple sweeps provide a guard against false negatives arising due to typographical errors, missing fields, or inconsistencies. For example, a person may have one last name in one database but another last name in another database, say because of a typo or a name change. He or she would be matched on Address, Data of Birth, and Gender. The algorithm will match the record on the identifiers that do not contain each of these categories of fields, thus avoiding nonmatches due to typographical errors, nicknames, missing fields, and other inconsistencies between databases. A record is determined to have found a match if a given identifier in TEAM is identical to at least one corresponding identifier in an identification database.

As shown in Table 1, the algorithm implemented in the Texas case conducts two sorts of sweeps through the data to find matching records. The Primary Sweeps match on Combinations A–F and M, and are run on all TEAM records. A–F correspond to matches obtained through the ADGN link indicators. M and SSN are matches between Texas State IDs and SSN9 for those cases for which such fields are available on the TEAM database. The analysis presented here focuses on Sweeps A through F, M and SSN.

Table 1. Combinations of fields used as matching identifiers, details. CSVDisplay Table

In addition, the implementation of the matching algorithm sought to find additional matches using a set of Secondary Sweeps performed on the TEAM records not matched in the Primary Sweeps. The secondary sweeps are shown in Table 1 as Combinations G–L. The secondary matches include additional variants, such as using middle initials, and matching separately on components of compound surnames. For example, we would attempt to match a voter named Ruth Bader Ginsberg to records of Ruth Bader Ginsberg, Ruth Ginsberg and Ruth Bader. For Federal databases, the Primary Sweeps are run against all qualifying Federal records with Texas addresses, while the Secondary Sweeps are run both against Texas-only records, as well as against the nationwide universe of the relevant Federal dataset.

By using multiple identifiers, the algorithm is developed to be sensitive to variations in names, such as nicknames and compound names, to typographical errors, and to missing information. By matching on identifiers constructed from a larger number of categories of fields (three or four), the algorithm exhausts all possible linkages among the identifiers that have a high likelihood of finding unique matches.

For each of the four state ID databases we matched to, we performed each match sequentially using STATA, appending indicators to the TEAM database following each sweep. For the federal databases, we converted the algorithm to SQL. We transmitted the cleaned and processed TEAM file to each federal agency’s database operator, who performed the procedures internally on their records. They, in turn, produced for us the TEAM file appended with information about matches and non-matches on each matching sweep.

The fourth phase of the matching process is the Data Gathering phase. The results of all matching sweeps are recorded for each individual TEAM record. This stage also appends indicators of deceased records or expired licenses from the Texas DPS data to TEAM. Most records matched on all or almost all indicators, but some only matched on one or two indicators. Individuals who matched on only one or two indicators tended to be those who had a typo or a change in one of the identifiers.

What about individuals who matched to two different records on two different matches in the same database? For instance, what happens if John Doe (a voter) matches to one John Doe based on the GDN sweep but a different John Doe based on the AGD sweep? We counted this person as having a matching record, but such an occurrence is exceedingly rare. Recall from Figure 1 that each of the triplet combinations of ADGN is nearly always unique within a database. Thus, two different sweeps will rarely match someone to two different records on a database.

Regarding computing, it is worth noting that the TEAM database is 13 GB; the DPS database is 25 GB. On account of security, processing had to be done on a local machine. We, as well as the federal agencies responsible for some of the matching, had a variety of experiences with the time it took to process the matches. The first implementation of the algorithm was performed in 2012 as part of the case Texas v. Holder. One loop through the data to match on the string First Name–Last Name/Date of Birth/Address using STATA could take several hours. Some federal agencies using SQL also reported hours-long computing time. When conducting the match in the context of the 2015 case, Veasey v. Perry, we upgraded software to 8 core STATA (from 2 core) on a computer with processors to accommodate. The computer performed one iteration of the matching algorithm in less than 30 min, compared with several hours. That improvement in speed was critical to be able to validate each step of the algorithm and to train the algorithm to catch any errors, trap special cases, and measure performance of the matching routine.