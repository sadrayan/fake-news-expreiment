{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from . import model\n",
    "from . import util\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    \"\"\"Argument parser.\n",
    "    Returns:\n",
    "    Dictionary of arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "      '--job-dir',\n",
    "      type=str,\n",
    "      required=True,\n",
    "      help='local or GCS location for writing checkpoints and exporting models')\n",
    "    parser.add_argument(\n",
    "      '--num-epochs',\n",
    "      type=int,\n",
    "      default=20,\n",
    "      help='number of times to go through the data, default=20')\n",
    "    parser.add_argument(\n",
    "      '--batch-size',\n",
    "      default=128,\n",
    "      type=int,\n",
    "      help='number of records to read during each training step, default=128')\n",
    "    parser.add_argument(\n",
    "      '--learning-rate',\n",
    "      default=.01,\n",
    "      type=float,\n",
    "      help='learning rate for gradient descent, default=.01')\n",
    "    parser.add_argument(\n",
    "      '--verbosity',\n",
    "      choices=['DEBUG', 'ERROR', 'FATAL', 'INFO', 'WARN'],\n",
    "      default='INFO')\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def train_and_evaluate(args):\n",
    "    \"\"\"Trains and evaluates the Keras model.\n",
    "    Uses the Keras model defined in model.py and trains on data loaded and\n",
    "    preprocessed in util.py. Saves the trained model in TensorFlow SavedModel\n",
    "    format to the path defined in part by the --job-dir argument.\n",
    "    Args:\n",
    "    args: dictionary of arguments - see get_args() for details\n",
    "    \"\"\"\n",
    "\n",
    "    train_x, train_y, eval_x, eval_y = util.load_data()\n",
    "\n",
    "    # dimensions\n",
    "    num_train_examples, input_dim = train_x.shape\n",
    "    num_eval_examples = eval_x.shape[0]\n",
    "\n",
    "    # Create the Keras Model\n",
    "    keras_model = model.create_keras_model(\n",
    "      input_dim=input_dim, learning_rate=args.learning_rate)\n",
    "\n",
    "    # Pass a numpy array by passing DataFrame.values\n",
    "    training_dataset = model.input_fn(\n",
    "      features=train_x.values,\n",
    "      labels=train_y,\n",
    "      shuffle=True,\n",
    "      num_epochs=args.num_epochs,\n",
    "      batch_size=args.batch_size)\n",
    "\n",
    "    # Pass a numpy array by passing DataFrame.values\n",
    "    validation_dataset = model.input_fn(\n",
    "      features=eval_x.values,\n",
    "      labels=eval_y,\n",
    "      shuffle=False,\n",
    "      num_epochs=args.num_epochs,\n",
    "      batch_size=num_eval_examples)\n",
    "\n",
    "    # Setup Learning Rate decay.\n",
    "    lr_decay_cb = tf.keras.callbacks.LearningRateScheduler(\n",
    "      lambda epoch: args.learning_rate + 0.02 * (0.5 ** (1 + epoch)),\n",
    "      verbose=True)\n",
    "\n",
    "    # Setup TensorBoard callback.\n",
    "    tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "      os.path.join(args.job_dir, 'keras_tensorboard'),\n",
    "      histogram_freq=1)\n",
    "\n",
    "    # Train model\n",
    "    keras_model.fit(\n",
    "      training_dataset,\n",
    "      steps_per_epoch=int(num_train_examples / args.batch_size),\n",
    "      epochs=args.num_epochs,\n",
    "      validation_data=validation_dataset,\n",
    "      validation_steps=1,\n",
    "      verbose=1,\n",
    "      callbacks=[lr_decay_cb, tensorboard_cb])\n",
    "\n",
    "    export_path = os.path.join(args.job_dir, 'keras_export')\n",
    "    tf.contrib.saved_model.save_keras_model(keras_model, export_path)\n",
    "    print('Model exported to: {}'.format(export_path))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = get_args()\n",
    "    tf.logging.set_verbosity(args.verbosity)\n",
    "    train_and_evaluate(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
